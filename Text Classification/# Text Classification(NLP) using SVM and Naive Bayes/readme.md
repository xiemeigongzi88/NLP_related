# Text Classification(NLP) using SVM and Naive Bayes
  When working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier.

  Dataset URL: https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv.

## Steps:
  Exploring the Data
  Text Pre-processing
  Prepare train and test data 
  Encoding
  Word Vectorization 
  Naive Bayes Classifier for Multinomial Models
  Support Vector Machine

## Reference:
  https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb
  https://github.com/tensorflow/workshops/blob/master/extras/keras-bag-of-words/keras-bow-model.ipynb
  https://datascience.stackexchange.com/questions/20076/word2vec-vs-sentence2vec-vs-doc2vec 
  https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568
